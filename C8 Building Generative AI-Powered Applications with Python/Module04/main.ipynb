{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'meta_llama'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmeta_llama\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MetaLlama2\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Initialize the model\u001b[39;00m\n\u001b[1;32m      4\u001b[0m model \u001b[38;5;241m=\u001b[39m MetaLlama2(model_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmeta-llama-2\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'meta_llama'"
     ]
    }
   ],
   "source": [
    "from meta_llama import MetaLlama2\n",
    "\n",
    "# Initialize the model\n",
    "model = MetaLlama2(model_name='meta-llama-2')\n",
    "\n",
    "# Generate text based on a prompt\n",
    "prompt = \"What is the future of artificial intelligence?\"\n",
    "generated_text = model.generate_text(prompt)\n",
    "\n",
    "print(\"Generated Text:\", generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sparkm/.local/lib/python3.12/site-packages/whisper/__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(fp, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " If I had 109 seconds with a 20 year old me, I would tell him, no one knows what the fuck they're doing. And that is the ultimate secret to life. What if I told him to embrace his chaos, to embrace the delusions, swim against the tide. To work 12 hours a day, 7 to the week, 365 days a year. Because the harsh reality of life is, you have to work extremely hard. The question is, when do you want to work hard? Just your early 20s, or slog the rest of your long ass life. What if I told him to find the smartest person in the room, and two excess inputs, to achieve those dreams that most are scared to even think of, and achieve all that in half the time. What if I told him, what would matter in 7 years, don't even spend 7 minutes on it. All you need are the balls to start, a brain to learn, and a heart to never give up. And you have all of that. Because the fact is, the finish line will never be inside. So don't be nervous. Noviceness comes from under confidence. Go take that step 100 times over, in a hundred different ways. And I guarantee you, you are already at the finish line. What if, now fuck this what ifs. If I could just keep a hand on Trump, that shoulder and whisper, life has no manual. So be carefree. Have conviction even if you don't get the results or recognition today. Maybe, talk to mom more often. Maybe, be grateful and spend more time with the loved ones. Maybe, skip the assignment and make the video. Because life can change in 2 seconds. You will fail a thousand times, but all you need is that. One big win.\n"
     ]
    }
   ],
   "source": [
    "import whisper\n",
    "\n",
    "# Load the Whisper model\n",
    "model = whisper.load_model(\"base\")\n",
    "\n",
    "# Transcribe the audio file\n",
    "result = model.transcribe(R\"audio.mp3\")\n",
    "\n",
    "# Output the transcription\n",
    "print(result[\"text\"])\n",
    "\n",
    "#make textfile of the transcription\n",
    "with open('transcription.txt', 'w') as f:\n",
    "    f.write(result[\"text\"])\n",
    "    f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
